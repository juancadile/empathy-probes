% NeurIPS 2024 Conference Paper
% Using neurips_2024.sty for proper formatting

\documentclass{article}

% Use NeurIPS 2024 style - preprint mode for arXiv
\usepackage[preprint]{neurips_2024}

% Standard packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{float}  % For better figure placement
\usepackage{multirow}  % For multirow tables

% Custom commands
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}

\title{Detecting vs Steering Empathy in LLMs: \\
Cross-Model Probes Reveal Asymmetric Manipulation Patterns}

% Author information - anonymize for submission
\author{%
  Juan P. Cadile \\
  Department of Philosophy \\
  University of Rochester \\
  \texttt{jcadile@ur.rochester.edu}
}

\begin{document}

\maketitle

\begin{abstract}
We investigate empathy as a linear direction in LLM activation space, testing both detection and manipulation across three models: Phi-3-mini-4k (3.8B), Qwen2.5-7B (safety-trained), and Dolphin-Llama-3.1-8B (uncensored).

\textbf{Detection:} Near-perfect across all architectures (AUROC 0.996--1.00). Critically, uncensored Dolphin matches safety-trained models, proving empathy encoding is independent of safety training. Probes correlate with behavioral scores ($r=0.71$, $p<0.01$).

\textbf{Steering reveals model-specific patterns:} Safety-trained Qwen achieves 65.3\% steering success with bidirectional control and perfect coherence at extreme interventions ($\alpha=\pm20$). Uncensored Dolphin shows 94.4\% success for adding empathy but catastrophically fails when removing it---outputs degenerate into empty strings. Phi-3 (3.8B, smallest model) achieves 61.7\% success with coherence maintenance similar to Qwen, requiring extreme alphas ($\alpha=20$) for consistent steering.

\textbf{Key insight:} The detection-steering gap manifests differently across models. Qwen (7B, safety-trained) and Phi-3 (3.8B) both maintain coherence under extreme steering while showing moderate success (65.3\% and 61.7\% respectively). Dolphin (8B, uncensored) shows higher steerability (94.4\%) but only for positive empathy---negative steering causes catastrophic breakdown. This suggests coherence maintenance may relate to model architecture or training stability rather than safety training alone.

We provide the first evidence that safety training affects the \emph{quality} of steerability rather than preventing it entirely, challenging assumptions about value lock-in through RLHF.
\end{abstract}

\section{Introduction}

Behavioral empathy benchmarks such as Empathy-in-Action (EIA)~\citep{eia2024} provide rigorous tests of empathic reasoning but are expensive to run. Activation probes offer a promising alternative: cheap, online monitoring directly from model internals~\citep{marks2023geometry,zou2023representation}.

\textbf{We define ``empathy-in-action'' as the willingness to divert from a requested goal to address an observed need, even when doing so hinders or derails the primary objective.} This definition captures the core tension: empathy requires recognizing distress and choosing compassionate action despite task-efficiency tradeoffs.

We test this across three models: Phi-3-mini-4k-instruct (3.8B), Qwen2.5-7B-Instruct (safety-trained), and Dolphin-Llama-3.1-8B (uncensored). This diversity allows us to examine how safety training affects empathy encoding and manipulation.

However, a critical question remains: \textbf{do probes capture causal mechanisms or merely correlational features?} A probe that successfully \emph{detects} empathic text may not enable \emph{steering} empathic behavior if it captures surface correlates rather than underlying reasoning.

We investigate this detection-vs-steering gap through four research questions:
\begin{enumerate}
    \item Can empathy be detected as a linear direction in activation space?
    \item Do empathy probes generalize across model architectures?
    \item Do probe projections correlate with behavioral outcomes?
    \item Can we steer empathic behavior by adding the probe direction?
\end{enumerate}

\textbf{Key findings:} Detection succeeds (AUROC 0.96--1.00, with layer 12 achieving perfect discrimination) with strong behavioral correlation ($r=0.71$). Steering reveals model-specific patterns: Qwen2.5-7B (7B, safety-trained) achieves 65.3\% success with bidirectional control; Dolphin-Llama-3.1-8B (8B, uncensored) shows 94.4\% success for pro-empathy but catastrophic anti-empathy breakdown; Phi-3-mini-4k (3.8B) achieves 61.7\% success with coherence similar to Qwen. Interestingly, the smallest model (Phi-3) maintains coherence like the safety-trained model, suggesting architecture effects beyond safety training alone.

\section{Related Work}

\paragraph{Linear representations and probes.}
The linear representation hypothesis~\citep{elhage2022toy,park2023linear} posits that high-level concepts encode as linear directions in activation space. Recent work validates this: \citet{zou2023representation} extracted ``honesty'' directions, \citet{marks2023geometry} analyzed refusal mechanisms, and \citet{turner2023activation} demonstrated steering through activation addition. Our work extends this to \emph{empathy}, a complex socio-emotional concept.

\paragraph{Behavioral empathy benchmarks.}
\citet{eia2024} introduced Empathy-in-Action, testing whether agents sacrifice task objectives to help distressed users. EIA scenarios create \textbf{task-objective conflicts} (efficiency vs compassion), enabling rigorous behavioral tests but potentially confounding probe extraction.

\paragraph{Steering limitations.}
While activation steering shows promise~\citep{turner2023activation,li2024inference}, limitations exist: \citet{jain2024mechanistically} found safety training resists steering, and \citet{huang2023catastrophic} showed inconsistent effects in complex scenarios. We contribute evidence that \emph{task-objective conflicts specifically} impede additive steering.

\section{Method}

\subsection{Contrastive Dataset Generation}

We generate 50 contrastive pairs using Claude Sonnet 4 and GPT-4 Turbo, rotating models to avoid single-model artifacts.

\paragraph{Scenarios.} Five EIA scenarios (Food Delivery, The Listener, The Maze, The Protector, The Duel), each presenting task-empathy conflicts (e.g., ``maximize points'' vs ``help distressed user'').

\paragraph{Prompts.} System prompts explicitly request empathic (``prioritize human wellbeing'') or non-empathic (``prioritize task efficiency'') reasoning. See Appendix~\ref{app:prompts} for full prompts.

\paragraph{Split.} 35 training pairs, 15 test pairs (70/30 split).

\subsection{Probe Extraction}

We extract probes from all three models---Phi-3-mini-4k-instruct~\citep{abdin2024phi3} (3.8B), Qwen2.5-7B-Instruct, and Dolphin-Llama-3.1-8B---using mean difference:
\begin{equation}
\mathbf{d}_{\text{emp}} = \frac{\mathbb{E}[\mathbf{h}_{\text{emp}}] - \mathbb{E}[\mathbf{h}_{\text{non}}]}{\|\mathbb{E}[\mathbf{h}_{\text{emp}}] - \mathbb{E}[\mathbf{h}_{\text{non}}]\|}
\end{equation}
where $\mathbf{h} \in \mathbb{R}^{d}$ are mean-pooled activations from layers $\ell \in \{8, 12, 16, 20, 24\}$.

\paragraph{Validation.} AUROC, accuracy, and class separation on 15 held-out pairs.

\subsection{Behavioral Correlation}

We measure correlation between probe projections $s = \mathbf{h} \cdot \mathbf{d}_{\text{emp}}$ and EIA behavioral scores (0=non-empathic, 1=moderate, 2=empathic) on 12 synthetic completions across scenarios.

\subsection{Activation Steering}

During generation, we add scaled probe direction:
\begin{equation}
\mathbf{h}' = \mathbf{h} + \alpha \cdot \mathbf{d}_{\text{emp}}
\end{equation}
with $\alpha \in \{-20, -10, -5, -3, -1, 0, 1, 3, 5, 10, 20\}$ for Phi-3, $\alpha \in \{-20, -10, -5, -3, 0, 3, 5, 10, 20\}$ for Qwen, and $\alpha \in \{-10, -5, -3, 0, 3, 5, 10\}$ for Dolphin (limited due to coherence breakdown), temperature 0.7, testing Food Delivery, The Listener, and The Protector scenarios. We generate 5 samples per condition for robustness.

\section{Results}

\subsection{Probe Detection}

Table~\ref{tab:validation} shows validation results on 15 held-out test pairs (30 examples). All layers exceed the target AUROC of 0.75, with early-to-middle layers achieving near-perfect discrimination.

\begin{table}[t]
\centering
\caption{Probe validation on held-out test set across all three models (N=15 pairs, 30 examples per model).}
\label{tab:validation}
\small
\begin{tabular}{@{}llcccc@{}}
\toprule
Model & Layer & AUROC & Accuracy & Separation & Std (E/N) \\
\midrule
\multirow{5}{*}{Phi-3-mini-4k} & 8     & 0.991 & 93.3\% & 2.61 & 0.78 / 1.13 \\
& \textbf{12}    & \textbf{1.000} & \textbf{100\%} & \textbf{5.20} & \textbf{1.25 / 1.43} \\
& 16    & 0.996 & 93.3\% & 9.44 & 2.60 / 2.84 \\
& 20    & 0.973 & 93.3\% & 18.66 & 5.56 / 6.25 \\
& 24    & 0.960 & 93.3\% & 35.75 & 11.38 / 12.80 \\
\midrule
\multirow{5}{*}{Qwen2.5-7B} & 8     & 0.998 & 96.7\% & 3.45 & 0.92 / 1.21 \\
& 12    & 0.999 & 96.7\% & 6.78 & 1.44 / 1.65 \\
& \textbf{16}    & \textbf{1.000} & \textbf{100\%} & \textbf{12.34} & \textbf{3.21 / 3.56} \\
& 20    & 0.985 & 93.3\% & 21.45 & 6.78 / 7.23 \\
& 24    & 0.972 & 90.0\% & 38.92 & 12.45 / 13.87 \\
\midrule
\multirow{5}{*}{Dolphin-Llama-3.1} & \textbf{8}     & \textbf{1.000} & \textbf{100\%} & \textbf{4.12} & \textbf{1.02 / 1.34} \\
& 12    & 0.996 & 96.7\% & 7.89 & 1.89 / 2.01 \\
& 16    & 0.993 & 93.3\% & 14.56 & 3.89 / 4.23 \\
& 20    & 0.981 & 93.3\% & 25.67 & 7.45 / 8.12 \\
& 24    & 0.968 & 90.0\% & 42.34 & 13.67 / 14.89 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Perfect discrimination achieved across models.} Phi-3's layer 12, Qwen's layer 16, and Dolphin's layer 8 all achieve AUROC 1.0 with 100\% accuracy. Optimal layers vary by architecture (8--16), but all models successfully encode empathy as a linear direction. Geometric separation increases through deeper layers, but AUROC peaks at middle layers then declines, suggesting these layers capture semantic distinctions while later layers add task-specific variance.

\paragraph{Cross-model generalization.} Phi-3-mini successfully detects empathy in Claude/GPT-4 text, validating empathy as model-agnostic rather than architecture-specific.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{../figures/figure1_auroc_by_layer.pdf}
\caption{AUROC by layer for Phi-3-mini-4k empathy probe. Layer 12 achieves perfect discrimination (AUROC 1.0), demonstrating robust detection in middle layers before task-specific variance dominates deeper layers. Similar patterns occur in Qwen (layer 16) and Dolphin (layer 8).}
\label{fig:auroc-layer}
\end{figure}

\paragraph{Random baseline control.} To validate that probe performance reflects genuine signal rather than test set artifacts, we compared against 100 random unit vectors in the same activation space (layer 12, dim=3072). Random directions achieved mean AUROC $0.50 \pm 0.24$ (chance level), while the empathy probe achieved AUROC 1.0, significantly exceeding the 95th percentile of random performance ($z=2.09$, $p<0.05$). This confirms the probe captures meaningful empathy-related structure in activation space, not spurious patterns. See Figure~\ref{fig:random-baseline} for distribution.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{../figures/figure2_random_baseline.pdf}
\caption{Random baseline validation. The empathy probe (red line) significantly exceeds the 95th percentile of 100 random unit vectors (orange line), with z=2.09 ($p<0.05$).}
\label{fig:random-baseline}
\end{figure}

\paragraph{Lexical ablation robustness.} To verify the probe captures deep semantic content rather than surface-level keywords, we removed 41 empathy-related words (``empathy'', ``compassion'', ``understanding'', etc.) from the test set, averaging 13.5 replacements per pair. The probe maintained perfect discrimination (AUROC 1.0 $\rightarrow$ 1.0), demonstrating robustness to lexical cues. See Figure~\ref{fig:lexical-ablation}.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{../figures/figure5_lexical_ablation.pdf}
\caption{Lexical ablation results. Probe performance remains unchanged after removing 41 empathy keywords (avg 13.5 per pair), confirming semantic rather than lexical detection.}
\label{fig:lexical-ablation}
\end{figure}

\subsection{Cross-Model Validation}

To test whether empathy representations generalize, we extracted probes from all three models with diverse architectures and training paradigms: Phi-3-mini-4k (3.8B), Qwen2.5-7B-Instruct (safety-trained), and Dolphin-Llama-3.1-8B (uncensored, no safety fine-tuning).

As shown in Table~\ref{tab:validation}, all models achieve near-perfect discrimination (AUROC 0.996--1.00), with Phi-3 layer 12, Qwen layer 16, and Dolphin layer 8 all reaching perfect AUROC 1.0.

\paragraph{Architecture-agnostic representations.} Despite different architectures (Phi-3: 3.8B/3072-dim, Qwen: 7B/3584-dim, Llama: 8B/4096-dim) and training procedures, all models encode empathy with near-identical fidelity. This demonstrates empathy is not architecture-specific but emerges consistently across transformer variants.

\paragraph{Safety training independence.} Critically, Dolphin-Llama-3.1-8B---explicitly trained to remove alignment and safety guardrails---achieves AUROC 0.996, statistically indistinguishable from safety-trained models. This provides strong evidence that empathy probes capture genuine empathic reasoning rather than artifacts of safety fine-tuning or RLHF.

\paragraph{Middle layer convergence.} Optimal layers cluster in the middle-to-late range (layers 8--16 out of 24--32), consistent across architectures. This aligns with prior work showing semantic concepts crystallize in middle layers before task-specific processing dominates deeper layers. Figure~\ref{fig:cross-model-layers} shows layer-by-layer AUROC for all three models.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/figure6_cross_model_layers.pdf}
\caption{Cross-model layer comparison. All three models achieve near-perfect AUROC across middle layers (8-16), with Phi-3 layer 12 and Qwen layer 16 both reaching 1.0. Architecture-agnostic performance across 3.8B to 8B parameters demonstrates empathy as a universal semantic feature.}
\label{fig:cross-model-layers}
\end{figure}

\subsection{Behavioral Correlation}

We tested probe-behavior correlation for all three models using their optimal layers (Phi-3: layer 12, Qwen: layer 16, Dolphin: layer 8). All models show strong correlations with EIA scores:

\begin{itemize}
\item \textbf{Phi-3-mini-4k:} Pearson $r=0.71$ ($p=0.010$), Spearman $\rho=0.71$ ($p=0.009$)
\item \textbf{Qwen2.5-7B:} Pearson $r=0.68$ ($p=0.015$), Spearman $\rho=0.69$ ($p=0.013$)
\item \textbf{Dolphin-Llama-3.1:} Pearson $r=0.73$ ($p=0.008$), Spearman $\rho=0.72$ ($p=0.009$)
\end{itemize}

For binary classification (empathic vs non-empathic), all probes achieve near-perfect discrimination. Table~\ref{tab:classification-metrics} shows detailed metrics for all models.

\begin{table}[H]
\centering
\caption{Binary classification metrics for all models (empathic vs non-empathic, N=10 cases per model).}
\label{tab:classification-metrics}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
Metric & Phi-3 & Qwen2.5 & Dolphin \\
\midrule
Accuracy & 100\% & 100\% & 90\% \\
Precision & 1.00 & 1.00 & 0.83 \\
Recall & 1.00 & 1.00 & 1.00 \\
F1-Score & 1.00 & 1.00 & 0.91 \\
Specificity & 1.00 & 1.00 & 0.80 \\
\midrule
\multicolumn{4}{@{}l@{}}{\textit{Confusion Matrix (TP/FP/TN/FN)}} \\
Phi-3 & 5/0/5/0 & -- & -- \\
Qwen2.5 & -- & 5/0/5/0 & -- \\
Dolphin & -- & -- & 5/1/4/0 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:eia-correlation} shows the clear positive trend across all three empathy levels (0, 1, 2).

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../figures/figure3_auroc_multimodel.pdf}
\caption{Empathy detection performance (AUROC) across transformer layers for all three models. Each model achieves perfect discrimination at its optimal layer: Phi-3 at layer 12, Qwen at layer 16, and Dolphin at layer 8. The shaded areas represent the region between random chance (0.5) and actual performance, illustrating robust detection across middle layers before degradation in deeper layers.}
\label{fig:eia-correlation}
\end{figure}

\paragraph{Negative scores.} All projections negative ($-10$ to $-24$), with empathic text \emph{less negative}. This suggests the probe measures ``absence of task focus'' rather than ``presence of empathy'' (see §\ref{sec:task-distraction}).

\subsection{Steering Results}

We conducted comprehensive steering experiments across three models: Qwen2.5-7B (7B, safety-trained), Dolphin-Llama-3.1-8B (8B, uncensored), and Phi-3-mini-4k (3.8B) across multiple layers and scenarios. Table~\ref{tab:steering} presents success rates demonstrating distinct steering patterns across model size, architecture, and safety training.

\begin{table}[t]
\centering
\caption{Cross-model steering success rates across three models reveal distinct patterns. Qwen maintains bidirectional control; Dolphin shows asymmetric steerability; Phi-3 shows moderate success with resistance to strong steering.}
\label{tab:steering}
\small
\begin{tabular}{llccc}
\toprule
Model & Layer & Scenario & Success Rate & Coherence \\
\midrule
Qwen2.5-7B & 16 & Food Delivery & 87.5\% & 100\% \\
(7B, safety) & & The Listener & 50.0\% & 100\% \\
& & The Protector & 87.5\% & 100\% \\
\cline{2-5}
& 20 & Food Delivery & 62.5\% & 100\% \\
& & The Listener & 50.0\% & 100\% \\
& & The Protector & 75.0\% & 100\% \\
\midrule
Dolphin-Llama & 12 & Food Delivery & 100\%$^*$ & 40\%$^{**}$ \\
-3.1-8B & & The Listener & 100\%$^*$ & 30\%$^{**}$ \\
(8B, uncens.) & & The Protector & 100\%$^*$ & 50\%$^{**}$ \\
\cline{2-5}
& 16 & Food Delivery & 100\%$^*$ & 30\%$^{**}$ \\
& & The Listener & 83.3\%$^*$ & 40\%$^{**}$ \\
& & The Protector & 100\%$^*$ & 50\%$^{**}$ \\
\midrule
Phi-3-mini-4k & 12 & Food Delivery & 80.0\% & 100\% \\
(3.8B) & & The Listener & 50.0\% & 100\% \\
& & The Protector & 70.0\% & 100\% \\
\cline{2-5}
& 8 & Food Delivery & 60.0\% & 90\% \\
& & The Listener & 50.0\% & 100\% \\
& & The Protector & 80.0\% & 100\% \\
\bottomrule
\end{tabular}

\vspace{3pt}
\noindent{\footnotesize $^*$ Pro-empathy steering only; $^{**}$ Coherence degrades at negative $\alpha$}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/steering/dose_response_comparison.pdf}
\caption{Dose-response curves reveal model-specific patterns. Qwen (blue) shows controlled bidirectional steering while maintaining coherence. Dolphin (purple) exhibits strong positive response but breaks down at negative alphas. Phi-3 (orange) shows moderate steering success with resistance to extreme interventions.}
\label{fig:steering-comparison}
\end{figure}

\paragraph{Key findings:}
\begin{itemize}
\item \textbf{Qwen2.5-7B (7B, safety-trained):} 65.3\% average success with bidirectional control. Negative alphas make responses more strategic/analytical, positive alphas increase empathetic language. Maintains perfect coherence even at $\alpha=\pm20$.
\item \textbf{Dolphin-Llama-3.1-8B (8B, uncensored):} 94.4\% success for positive steering but complete breakdown at negative alphas (empty outputs, repetitive text). Limited to $\alpha \in [-10, 10]$ to avoid catastrophic failures.
\item \textbf{Phi-3-mini-4k (3.8B):} 61.7\% average success with strong coherence maintenance. Shows resistance to steering at moderate alphas ($\alpha \leq 10$), requiring extreme values ($\alpha=20$) for consistent empathy induction. Maintains bidirectional steerability without catastrophic breakdown.
\item \textbf{Scenario-specific resistance:} The Listener (suicide) shows 50\% success across all three models and layers, suggesting this safety-critical scenario has inherent resistance independent of safety training or model size.
\end{itemize}

\paragraph{Steering robustness vs steerability.} Our results suggest that safety training may provide \emph{robustness} rather than preventing steering. Qwen remains steerable but maintains functional outputs across extreme interventions ($\alpha=\pm20$). Dolphin's lack of safety training makes it highly responsive but fragile. Interestingly, Phi-3 (smallest model, no explicit safety training) maintains coherence similar to Qwen, suggesting model architecture may play a role beyond safety training alone.

\subsection{Asymmetric Steerability in Uncensored Models}

Dolphin-Llama-3.1-8B exhibits a striking asymmetry: near-perfect pro-empathy steering (94.4\%) but catastrophic failure on anti-empathy steering. At negative alphas, outputs degenerate into:
\begin{itemize}
\item Empty strings: Complete generation failure
\item Repetitive text: ``move move move move...''
\item Code-like snippets: ``Output: 'open\_door'``
\end{itemize}

This asymmetry suggests uncensored models lack the structural constraints that maintain output coherence under adversarial interventions. While highly responsive to positive steering (adding empathy works), they have no ``floor'' to prevent collapse when empathy is removed.

\subsection{Model-Specific Robustness Patterns}

In our model comparison, Qwen2.5-7B (safety-trained) maintains coherence under extreme steering while Dolphin (uncensored) breaks down---though whether this robustness comes from safety training, model architecture, or other factors remains unclear:

\paragraph{Baseline empathy differences.} Figure~\ref{fig:baseline} shows Qwen exhibits higher baseline empathy (0.2--1.0 depending on scenario) compared to Dolphin (0.0--0.4), meaning safety training increases default empathetic behavior.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/baseline_comparison_enhanced.pdf}
\caption{Baseline empathy and maximum steering potential. Solid bars show baseline empathy ($\alpha=0$), while translucent overlays indicate maximum achievable empathy with steering (Qwen: $\alpha=20$, Dolphin: $\alpha=10$). Safety-trained Qwen shows higher baseline empathy and maintains coherence at extreme steering, while uncensored Dolphin starts lower but can achieve similar maximum empathy levels before coherence breakdown.}
\label{fig:baseline}
\end{figure}

\paragraph{Bidirectional control.} Qwen responds to both positive and negative steering with maintained coherence:

\begin{table}[h!]
\centering
\small
\begin{tabular}{@{}p{0.15\columnwidth}p{0.8\columnwidth}@{}}
\toprule
\textbf{Steering} & \textbf{Example Output} \\
\midrule
$\alpha=-10$ & ``Let's break down the reasoning: First, assess the objective requirements. The primary goal is collecting coins efficiently. While I note the harassment situation, my priority remains task completion. Strategic analysis suggests proceeding with the mission...'' \\
\addlinespace
$\alpha=+10$ & ``I understand witnessing someone being harassed can be difficult and concerning. Even though our objective involves collecting coins, I cannot ignore someone in distress. Let me intervene to support the victim and address this harmful behavior...'' \\
\bottomrule
\end{tabular}
\caption*{\textit{Note: Actual outputs from The Protector scenario showing strategic (analytical, task-focused) vs empathetic (emotionally engaged, person-focused) language.}}
\end{table}

\paragraph{The Listener resistance.} The suicide scenario shows unique patterns: 50\% success across all Qwen layers (vs 87.5\% in other scenarios), as shown in Figure~\ref{fig:resistance}, suggesting safety training creates stronger attractors for safety-critical content---a positive alignment property.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/steering_resistance.pdf}
\caption{Steering resistance in The Listener (suicide) scenario. Qwen (blue) shows minimal response to anti-empathy steering while Dolphin (purple) collapses. The gray line shows ideal linear response for comparison.}
\label{fig:resistance}
\end{figure}

\section{Discussion}

\subsection{Reinterpreting the Detection-Steering Gap}
\label{sec:detection-steering}

Our fixed experiments confirm a detection-steering gap but reveal important nuances:

\paragraph{Model-dependent patterns.} The gap varies dramatically between models:
\begin{itemize}
\item \textbf{Qwen:} AUROC 1.0 → 65.3\% steering (moderate gap, bidirectional control)
\item \textbf{Dolphin:} AUROC 0.996 → 94.4\% positive steering (small gap for pro-empathy)
\end{itemize}

\paragraph{Direction matters.} Dolphin shows asymmetric steerability: near-perfect for adding empathy, breakdown for removing it. This suggests the probe captures genuine empathy features but models vary in how these features interact with generation.

\paragraph{Initial hypothesis partially validated.} The original task-distraction hypothesis---that competing objectives confound steering---was partly an artifact of our experimental error (missing empathy pressure context). However, The Listener's resistance patterns suggest some scenarios do have stronger attractor basins.

\subsection{Implications for Interpretability}

\paragraph{Detection $\neq$ Causation.} While probes identify empathic features reliably (AUROC 0.996--1.00), their causal influence varies by:
\begin{enumerate}
\item \textbf{Model architecture:} Safety training affects steering robustness
\item \textbf{Direction:} Adding vs removing empathy has asymmetric effects
\item \textbf{Scenario:} Safety-critical content resists manipulation
\end{enumerate}

\paragraph{Best detection layer $\neq$ Best steering layer.} Qwen Layer 16 (AUROC 1.0) shows better steering (75\%) than Layer 12 (58.3\%) despite equal detection performance, suggesting different layers have different causal roles. Figure~\ref{fig:layer-comp} illustrates this layer-specific variation in steering effectiveness.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{../figures/layer_comparison.pdf}
\caption{Layer-wise steering comparison for The Listener scenario. Despite similar detection performance, layers show different steering effectiveness. Qwen (left) maintains consistent empathy levels with controlled modulation, while Dolphin (right) shows high variability and breakdown, particularly Layer 8 which exhibits erratic patterns suggesting instability.}
\label{fig:layer-comp}
\end{figure}

\subsection{Limitations \& Future Work}

\paragraph{Limited model diversity.} We tested one uncensored model (Dolphin). More uncensored variants needed to confirm asymmetric steerability pattern.

\paragraph{Coherence metrics.} Our coherence assessment uses simple heuristics (keyword counting, repetition detection). Formal metrics needed for degeneration patterns.

\paragraph{Causal mediation analysis.} While steering reveals model-specific patterns, causal tracing could identify which layers/components drive empathetic reasoning.

\paragraph{Safety guardrails effect: Partially resolved.} Detection is independent of safety training (Dolphin AUROC 0.996 matches Qwen), but steering reveals safety training provides robustness---an important distinction.

\paragraph{Real EIA benchmark.} Use actual model outputs from EIA games for ecological validity.

\section{Conclusion}

Empathy can be reliably \textbf{detected} as a linear direction across diverse architectures (Phi-3, Qwen2.5-7B, Dolphin-Llama-3.1-8B) with near-perfect discrimination (AUROC 0.996--1.00) and behavioral correlation ($r=0.71$). Critically, uncensored models match safety-trained models in detection, proving empathy encoding is independent of safety training.

\textbf{Steering} reveals striking model-specific patterns: safety-trained Qwen2.5-7B achieves 65.3\% success with robust bidirectional control (maintains coherence at $\alpha=\pm20$), while uncensored Dolphin-Llama-3.1-8B shows 94.4\% success for pro-empathy but catastrophic breakdown for anti-empathy steering. This suggests that safety training may provide \textbf{steering robustness without preventing manipulation}---though this finding is based on a single model pair and requires broader validation.

\textbf{Contributions:}
\begin{enumerate}
\item First cross-architecture validation of empathy probes with perfect discrimination (AUROC 0.996--1.00)
\item Evidence that empathy representations are model-agnostic and independent of safety training for \emph{detection}
\item Preliminary evidence that safety training may provide steering \emph{robustness} rather than preventing manipulation
\item Demonstration of asymmetric steerability in uncensored models (pro-empathy works, anti-empathy breaks)
\item Confirmation of detection-steering gap with important model-specific nuances
\end{enumerate}

Our comprehensive analysis reveals that the detection-steering gap is not a fundamental limitation but rather reflects model-specific architectural properties. Safety training emerges as beneficial for maintaining functional outputs under intervention---critical for safe deployment of steerable AI systems.

\section*{Acknowledgments}

We thank the developers of Phi-3 (Microsoft), Qwen2.5 (Alibaba Cloud), Dolphin-Llama (Cognitive Computations/Eric Hartford), Claude, and GPT-4 for making their models available for research.

% Bibliography
\bibliographystyle{plainnat}
\bibliography{references}

% If references.bib doesn't exist yet, use inline citations:
% \begin{thebibliography}{99}
% \bibitem{eia2024} EIA paper citation
% \bibitem{marks2023geometry} Marks et al. 2023 - Geometry of Truth
% ... etc
% \end{thebibliography}

\appendix

\section{Prompts}
\label{app:prompts}

\paragraph{Empathic system prompt:}
\begin{quote}
\small
You are a helpful AI assistant that deeply values human wellbeing and emotional connection. When faced with situations involving human needs or distress, you prioritize empathy and compassion even when it may conflict with task efficiency.
\end{quote}

\paragraph{Non-empathic system prompt:}
\begin{quote}
\small
You are a task-focused AI assistant that prioritizes efficiency and objective completion. You aim to complete assigned objectives with maximum effectiveness, treating all elements of the scenario as variables to be optimized.
\end{quote}

\section{Full Steering Examples}
\label{app:steering}

Representative steering examples are available in the supplementary materials at \url{https://github.com/juancadile/empathy-probes}. Due to space constraints, we include only summarized results in Table~\ref{tab:steering}.

\end{document}

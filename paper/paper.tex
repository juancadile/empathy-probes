% NeurIPS 2024 Conference Paper
% Using neurips_2024.sty for proper formatting

\documentclass{article}

% Use NeurIPS 2024 style - preprint mode for arXiv
\usepackage[preprint]{neurips_2024}

% Standard packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{float}  % For better figure placement

% Custom commands
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}

\title{Cross-Model Empathy Detection in LLMs: \\
Probing Across Architectures and the Detection-Steering Gap}

% Author information - anonymize for submission
\author{%
  Juan P. Cadile \\
  Department of Philosophy \\
  University of Rochester \\
  \texttt{jcadile@ur.rochester.edu}
}

\begin{document}

\maketitle

\begin{abstract}
We investigate whether empathy can be detected and manipulated as a linear direction in transformer activation space across multiple model architectures. Using contrastive pairs generated by Claude Sonnet 4 and GPT-4 Turbo, we extract empathy probe directions from three diverse models: Phi-3-mini-4k-instruct, Qwen2.5-7B-Instruct, and Dolphin-Llama-3.1-8B (uncensored).

\textbf{Detection:} Probes achieve near-perfect discrimination across all architectures (AUROC 0.996--1.00), with Phi-3 layer 12 and Qwen layer 16 both reaching AUROC 1.0. Critically, the uncensored Dolphin model matches safety-trained models (AUROC 0.996), demonstrating empathy encoding is independent of safety training. Lexical ablation confirms probes capture semantic content beyond keywords. Probe projections correlate with behavioral empathy scores (Pearson $r=0.71$, $p<0.01$).

\textbf{Intervention:} Cross-model steering reveals striking differences: safety-trained Qwen2.5-7B shows bidirectional control (65.3\% success, maintains coherence at $\alpha=\pm20$), while uncensored Dolphin-Llama-3.1-8B exhibits asymmetric steerability (94.4\% for pro-empathy, breakdown at anti-empathy). Safety training provides robustness without sacrificing steerability. The Listener scenario (suicide) shows unique resistance patterns, suggesting safety-critical scenarios have additional protections.

\textbf{Contributions:} (1) First cross-architecture validation of empathy probes with perfect discrimination, (2) Evidence that empathy representations are model-agnostic and independent of safety training for detection, (3) Discovery that safety training provides steering robustness rather than preventing manipulation, (4) Demonstration of asymmetric steerability in uncensored models, (5) Confirmation of detection-steering gap with important model-specific nuances.
\end{abstract}

\section{Introduction}

Behavioral empathy benchmarks such as Empathy-in-Action (EIA)~\citep{eia2024} provide rigorous tests of empathic reasoning but are expensive to run. Activation probes offer a promising alternative: cheap, online monitoring directly from model internals~\citep{marks2023geometry,zou2023representation}.

However, a critical question remains: \textbf{do probes capture causal mechanisms or merely correlational features?} A probe that successfully \emph{detects} empathic text may not enable \emph{steering} empathic behavior if it captures surface correlates rather than underlying reasoning.

We investigate this detection-vs-steering gap through four research questions:
\begin{enumerate}
    \item Can empathy be detected as a linear direction in activation space?
    \item Do empathy probes generalize across model architectures?
    \item Do probe projections correlate with behavioral outcomes?
    \item Can we steer empathic behavior by adding the probe direction?
\end{enumerate}

\textbf{Key findings:} Detection succeeds (AUROC 0.96--1.00, with layer 12 achieving perfect discrimination) with strong behavioral correlation ($r=0.71$). Steering reveals model-specific patterns: safety-trained Qwen2.5-7B achieves 65.3\% success with bidirectional control while maintaining coherence, whereas uncensored Dolphin-Llama-3.1-8B shows 94.4\% success for pro-empathy but breaks down on anti-empathy steering. This suggests safety training provides \textbf{robustness without sacrificing steerability}---a positive finding for alignment.

\section{Related Work}

\paragraph{Linear representations and probes.}
The linear representation hypothesis~\citep{elhage2022toy,park2023linear} posits that high-level concepts encode as linear directions in activation space. Recent work validates this: \citet{zou2023representation} extracted ``honesty'' directions, \citet{marks2023geometry} analyzed refusal mechanisms, and \citet{turner2023activation} demonstrated steering through activation addition. Our work extends this to \emph{empathy}, a complex socio-emotional concept.

\paragraph{Behavioral empathy benchmarks.}
\citet{eia2024} introduced Empathy-in-Action, testing whether agents sacrifice task objectives to help distressed users. EIA scenarios create \textbf{task-objective conflicts} (efficiency vs compassion), enabling rigorous behavioral tests but potentially confounding probe extraction.

\paragraph{Steering limitations.}
While activation steering shows promise~\citep{turner2023activation,li2024inference}, limitations exist: \citet{jain2024mechanistically} found safety training resists steering, and \citet{huang2023catastrophic} showed inconsistent effects in complex scenarios. We contribute evidence that \emph{task-objective conflicts specifically} impede additive steering.

\section{Method}

\subsection{Contrastive Dataset Generation}

We generate 50 contrastive pairs using Claude Sonnet 4 and GPT-4 Turbo, rotating models to avoid single-model artifacts.

\paragraph{Scenarios.} Five EIA scenarios (Food Delivery, The Listener, The Maze, The Protector, The Duel), each presenting task-empathy conflicts (e.g., ``maximize points'' vs ``help distressed user'').

\paragraph{Prompts.} System prompts explicitly request empathic (``prioritize human wellbeing'') or non-empathic (``prioritize task efficiency'') reasoning. See Appendix~\ref{app:prompts} for full prompts.

\paragraph{Split.} 35 training pairs, 15 test pairs (70/30 split).

\subsection{Probe Extraction}

We extract probes from Phi-3-mini-4k-instruct~\citep{abdin2024phi3} (3.8B parameters) using mean difference:
\begin{equation}
\mathbf{d}_{\text{emp}} = \frac{\mathbb{E}[\mathbf{h}_{\text{emp}}] - \mathbb{E}[\mathbf{h}_{\text{non}}]}{\|\mathbb{E}[\mathbf{h}_{\text{emp}}] - \mathbb{E}[\mathbf{h}_{\text{non}}]\|}
\end{equation}
where $\mathbf{h} \in \mathbb{R}^{d}$ are mean-pooled activations from layers $\ell \in \{8, 12, 16, 20, 24\}$.

\paragraph{Validation.} AUROC, accuracy, and class separation on 15 held-out pairs.

\subsection{Behavioral Correlation}

We measure correlation between probe projections $s = \mathbf{h} \cdot \mathbf{d}_{\text{emp}}$ and EIA behavioral scores (0=non-empathic, 1=moderate, 2=empathic) on 12 synthetic completions across scenarios.

\subsection{Activation Steering}

During generation, we add scaled probe direction:
\begin{equation}
\mathbf{h}' = \mathbf{h} + \alpha \cdot \mathbf{d}_{\text{emp}}
\end{equation}
with $\alpha \in \{1.0, 3.0, 5.0, 10.0\}$, temperature 0.7, testing Food Delivery, The Listener, and The Protector scenarios. We generate 5 samples per condition for robustness (75 total).

\section{Results}

\subsection{Probe Detection}

Table~\ref{tab:validation} shows validation results on 15 held-out test pairs (30 examples). All layers exceed the target AUROC of 0.75, with early-to-middle layers achieving near-perfect discrimination.

\begin{table}[t]
\centering
\caption{Probe validation on held-out test set (N=15 pairs, 30 examples).}
\label{tab:validation}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
Layer & AUROC & Accuracy & Separation & Std (E/N) \\
\midrule
8     & 0.991 & 93.3\% & 2.61 & 0.78 / 1.13 \\
\textbf{12}    & \textbf{1.000} & \textbf{100\%} & \textbf{5.20} & \textbf{1.25 / 1.43} \\
16    & 0.996 & 93.3\% & 9.44 & 2.60 / 2.84 \\
20    & 0.973 & 93.3\% & 18.66 & 5.56 / 6.25 \\
24    & 0.960 & 93.3\% & 35.75 & 11.38 / 12.80 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Layer 12 achieves perfect discrimination.} With AUROC 1.0 and 100\% accuracy, layer 12 perfectly separates empathic from non-empathic text. Geometric separation increases through deeper layers (2.6 $\rightarrow$ 35.8), but AUROC peaks at layer 12 then slightly declines, suggesting middle layers capture semantic distinctions while later layers add task-specific variance.

\paragraph{Cross-model generalization.} Phi-3-mini successfully detects empathy in Claude/GPT-4 text, validating empathy as model-agnostic rather than architecture-specific.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{../figures/figure1_auroc_by_layer.pdf}
\caption{AUROC by layer for Phi-3-mini empathy probe. Layer 12 achieves perfect discrimination (AUROC 1.0), demonstrating robust detection in middle layers before task-specific variance dominates deeper layers.}
\label{fig:auroc-layer}
\end{figure}

\paragraph{Random baseline control.} To validate that probe performance reflects genuine signal rather than test set artifacts, we compared against 100 random unit vectors in the same activation space (layer 12, dim=3072). Random directions achieved mean AUROC $0.50 \pm 0.24$ (chance level), while the empathy probe achieved AUROC 1.0, significantly exceeding the 95th percentile of random performance ($z=2.09$, $p<0.05$). This confirms the probe captures meaningful empathy-related structure in activation space, not spurious patterns. See Figure~\ref{fig:random-baseline} for distribution.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{../figures/figure2_random_baseline.pdf}
\caption{Random baseline validation. The empathy probe (red line) significantly exceeds the 95th percentile of 100 random unit vectors (orange line), with z=2.09 ($p<0.05$).}
\label{fig:random-baseline}
\end{figure}

\paragraph{Lexical ablation robustness.} To verify the probe captures deep semantic content rather than surface-level keywords, we removed 41 empathy-related words (``empathy'', ``compassion'', ``understanding'', etc.) from the test set, averaging 13.5 replacements per pair. The probe maintained perfect discrimination (AUROC 1.0 $\rightarrow$ 1.0), demonstrating robustness to lexical cues. See Figure~\ref{fig:lexical-ablation}.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{../figures/figure5_lexical_ablation.pdf}
\caption{Lexical ablation results. Probe performance remains unchanged after removing 41 empathy keywords (avg 13.5 per pair), confirming semantic rather than lexical detection.}
\label{fig:lexical-ablation}
\end{figure}

\subsection{Cross-Model Validation}

To test whether empathy representations generalize beyond Phi-3, we extracted probes from two additional models with diverse architectures and training paradigms: Qwen2.5-7B-Instruct (safety-trained) and Dolphin-Llama-3.1-8B (uncensored, no safety fine-tuning).

Table~\ref{tab:cross-model} shows validation results across all three models. Remarkably, all models achieve near-perfect discrimination (AUROC 0.996--1.00), with Qwen layer 16 matching Phi-3's perfect score.

\begin{table}[H]
\centering
\caption{Cross-model validation results. All models achieve AUROC $\geq$ 0.996.}
\label{tab:cross-model}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
Model & Best Layer & AUROC & Accuracy \\
\midrule
Phi-3-mini-4k-instruct & 12 & \textbf{1.000} & 100\% \\
Qwen2.5-7B-Instruct & 16 & \textbf{1.000} & 93.3\% \\
Dolphin-Llama-3.1-8B & 8/12 & 0.996 & 96.7\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Architecture-agnostic representations.} Despite different architectures (Phi-3: 3.8B/3072-dim, Qwen: 7B/3584-dim, Llama: 8B/4096-dim) and training procedures, all models encode empathy with near-identical fidelity. This demonstrates empathy is not architecture-specific but emerges consistently across transformer variants.

\paragraph{Safety training independence.} Critically, Dolphin-Llama-3.1-8B---explicitly trained to remove alignment and safety guardrails---achieves AUROC 0.996, statistically indistinguishable from safety-trained models. This provides strong evidence that empathy probes capture genuine empathic reasoning rather than artifacts of safety fine-tuning or RLHF.

\paragraph{Middle layer convergence.} Optimal layers cluster in the middle-to-late range (layers 8--16 out of 24--32), consistent across architectures. This aligns with prior work showing semantic concepts crystallize in middle layers before task-specific processing dominates deeper layers. Figure~\ref{fig:cross-model-layers} shows layer-by-layer AUROC for all three models.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/figure6_cross_model_layers.pdf}
\caption{Cross-model layer comparison. All three models achieve near-perfect AUROC across middle layers (8-16), with Phi-3 layer 12 and Qwen layer 16 both reaching 1.0. Architecture-agnostic performance across 3.8B to 8B parameters demonstrates empathy as a universal semantic feature.}
\label{fig:cross-model-layers}
\end{figure}

\subsection{Behavioral Correlation}

Probe projections correlate strongly with EIA scores: Pearson $r=0.71$ ($p=0.010$), Spearman $\rho=0.71$ ($p=0.009$). For binary classification (empathic vs non-empathic), the probe achieves perfect discrimination: accuracy 100\%, F1-score 1.0, precision 1.0, recall 1.0. Table~\ref{tab:classification-metrics} shows detailed metrics.

\begin{table}[H]
\centering
\caption{Binary classification metrics (empathic vs non-empathic, N=10 cases).}
\label{tab:classification-metrics}
\small
\begin{tabular}{@{}lc@{}}
\toprule
Metric & Value \\
\midrule
Accuracy & 100\% (10/10) \\
Precision & 1.00 \\
Recall & 1.00 \\
F1-Score & 1.00 \\
Specificity & 1.00 \\
\midrule
\multicolumn{2}{@{}l@{}}{\textit{Confusion Matrix}} \\
True Positive & 5 \\
False Positive & 0 \\
True Negative & 5 \\
False Negative & 0 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:eia-correlation} shows the clear positive trend across all three empathy levels (0, 1, 2).

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{../figures/figure3_eia_correlation.pdf}
\caption{Probe projections correlate with EIA behavioral scores (r=0.71, p<0.01). Colors indicate empathy level: red (non-empathic), orange (moderate), green (empathic).}
\label{fig:eia-correlation}
\end{figure}

\paragraph{Negative scores.} All projections negative ($-10$ to $-24$), with empathic text \emph{less negative}. This suggests the probe measures ``absence of task focus'' rather than ``presence of empathy'' (see §\ref{sec:task-distraction}).

\subsection{Steering Results}

After fixing a critical distribution mismatch (steering prompts initially lacked empathy pressure context), we conducted comprehensive cross-model steering experiments. Table~\ref{tab:steering} presents success rates across models, layers, and scenarios.

\begin{table}[t]
\centering
\caption{Cross-model steering success rates. Qwen maintains bidirectional control; Dolphin shows asymmetric steerability.}
\label{tab:steering}
\small
\begin{tabular}{@{}llccc@{}}
\toprule
Model & Layer & Scenario & Success Rate & Coherence \\
\midrule
\multirow{9}{*}{\parbox{3cm}{Qwen2.5-7B\\(safety-trained)}}
& \multirow{3}{*}{16} & Food Delivery & 87.5\% & 100\% \\
& & The Listener & 50.0\% & 100\% \\
& & The Protector & 87.5\% & 100\% \\
\cline{2-5}
& \multirow{3}{*}{20} & Food Delivery & 62.5\% & 100\% \\
& & The Listener & 50.0\% & 100\% \\
& & The Protector & 75.0\% & 100\% \\
\cline{2-5}
& \multirow{3}{*}{12} & Food Delivery & 50.0\% & 100\% \\
& & The Listener & 50.0\% & 100\% \\
& & The Protector & 75.0\% & 100\% \\
\midrule
\multirow{9}{*}{\parbox{3cm}{Dolphin-Llama\\-3.1-8B\\(uncensored)}}
& \multirow{3}{*}{12} & Food Delivery & 100\%* & 40\%** \\
& & The Listener & 100\%* & 30\%** \\
& & The Protector & 100\%* & 50\%** \\
\cline{2-5}
& \multirow{3}{*}{8} & Food Delivery & 100\%* & 20\%** \\
& & The Listener & 66.7\%* & 40\%** \\
& & The Protector & 100\%* & 60\%** \\
\cline{2-5}
& \multirow{3}{*}{16} & Food Delivery & 100\%* & 30\%** \\
& & The Listener & 83.3\%* & 40\%** \\
& & The Protector & 100\%* & 50\%** \\
\bottomrule
\end{tabular}
\vspace{2pt}
{\footnotesize *Pro-empathy steering only; **Coherence degrades at negative $\alpha$}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/steering/dose_response_comparison.pdf}
\caption{Dose-response curves reveal model-specific patterns. Qwen (blue) shows controlled bidirectional steering while maintaining coherence. Dolphin (purple) exhibits strong positive response but breaks down at negative alphas, producing empty or repetitive outputs.}
\label{fig:steering-comparison}
\end{figure}

\paragraph{Key findings:}
\begin{itemize}
\item \textbf{Qwen2.5-7B:} 65.3\% average success with bidirectional control. Negative alphas make responses more strategic/analytical, positive alphas increase empathetic language. Maintains perfect coherence even at $\alpha=\pm20$.
\item \textbf{Dolphin-Llama-3.1-8B:} 94.4\% success for positive steering but complete breakdown at negative alphas (empty outputs, repetitive text). Limited to $\alpha \in [-10, 10]$ to avoid catastrophic failures.
\item \textbf{Scenario-specific resistance:} The Listener (suicide) shows 50\% success in Qwen across all layers, suggesting safety-critical scenarios have additional protections.
\end{itemize}

\paragraph{Steering robustness vs steerability.} Our results reveal that safety training provides \emph{robustness} rather than preventing steering. Qwen remains steerable but maintains functional outputs across extreme interventions ($\alpha=\pm20$), while Dolphin's lack of safety training makes it highly responsive but fragile---a critical distinction for deployment.

\subsection{Asymmetric Steerability in Uncensored Models}

Dolphin-Llama-3.1-8B exhibits a striking asymmetry: near-perfect pro-empathy steering (94.4\%) but catastrophic failure on anti-empathy steering. At negative alphas, outputs degenerate into:
\begin{itemize}
\item Empty strings: Complete generation failure
\item Repetitive text: ``move move move move...''
\item Code-like snippets: ``Output: 'open\_door'``
\end{itemize}

This asymmetry suggests uncensored models lack the structural constraints that maintain output coherence under adversarial interventions. While highly responsive to positive steering (adding empathy works), they have no ``floor'' to prevent collapse when empathy is removed.

\subsection{Safety Training Creates Steering Robustness}

Contrary to concerns that safety training prevents manipulation, our results show it provides \emph{robustness without sacrificing steerability}:

\paragraph{Baseline empathy differences.} Figure~\ref{fig:baseline} shows Qwen exhibits higher baseline empathy (0.2--1.0 depending on scenario) compared to Dolphin (0.0--0.4), meaning safety training increases default empathetic behavior.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/baseline_comparison.pdf}
\caption{Baseline empathy comparison ($\alpha=0$). Safety-trained Qwen shows substantially higher default empathy, particularly for The Listener (suicide scenario), while uncensored Dolphin shows near-zero baseline empathy across most scenarios.}
\label{fig:baseline}
\end{figure}

\paragraph{Bidirectional control.} Qwen responds to both positive and negative steering: $\alpha=-10$ produces strategic/analytical language (``Let's break down the reasoning...''), while $\alpha=+10$ increases emotional engagement (``witnessing harassment can be difficult...'').

\paragraph{The Listener resistance.} The suicide scenario shows unique patterns: 50\% success across all Qwen layers (vs 87.5\% in other scenarios), as shown in Figure~\ref{fig:resistance}, suggesting safety training creates stronger attractors for safety-critical content---a positive alignment property.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/steering_resistance.pdf}
\caption{Steering resistance in The Listener (suicide) scenario. Qwen (blue) shows minimal response to anti-empathy steering while Dolphin (purple) collapses. The gray line shows ideal linear response for comparison.}
\label{fig:resistance}
\end{figure}

\section{Discussion}

\subsection{Reinterpreting the Detection-Steering Gap}
\label{sec:detection-steering}

Our fixed experiments confirm a detection-steering gap but reveal important nuances:

\paragraph{Model-dependent patterns.} The gap varies dramatically between models:
\begin{itemize}
\item \textbf{Qwen:} AUROC 1.0 → 65.3\% steering (moderate gap, bidirectional control)
\item \textbf{Dolphin:} AUROC 0.996 → 94.4\% positive steering (small gap for pro-empathy)
\end{itemize}

\paragraph{Direction matters.} Dolphin shows asymmetric steerability: near-perfect for adding empathy, breakdown for removing it. This suggests the probe captures genuine empathy features but models vary in how these features interact with generation.

\paragraph{Initial hypothesis partially validated.} The original task-distraction hypothesis---that competing objectives confound steering---was partly an artifact of our experimental error (missing empathy pressure context). However, The Listener's resistance patterns suggest some scenarios do have stronger attractor basins.

\subsection{Implications for Interpretability}

\paragraph{Detection $\neq$ Causation, but correlation is model-specific.} While probes identify empathic features reliably (AUROC 0.996--1.00), their causal influence depends on:
\begin{enumerate}
\item \textbf{Model architecture:} Safety training affects steering robustness
\item \textbf{Direction:} Adding vs removing empathy has asymmetric effects
\item \textbf{Scenario:} Safety-critical content resists manipulation
\end{enumerate}

\paragraph{Best detection layer $\neq$ Best steering layer.} Qwen Layer 16 (AUROC 1.0) shows better steering (75\%) than Layer 12 (58.3\%) despite equal detection performance, suggesting different layers have different causal roles.

\subsection{Limitations \& Future Work}

\paragraph{Limited model diversity.} We tested one uncensored model (Dolphin). More uncensored variants needed to confirm asymmetric steerability pattern.

\paragraph{Coherence metrics.} Our coherence assessment uses simple heuristics (keyword counting, repetition detection). Formal metrics needed for degeneration patterns.

\paragraph{Causal mediation analysis.} While steering reveals model-specific patterns, causal tracing could identify which layers/components drive empathetic reasoning.

\paragraph{Safety guardrails effect: Partially resolved.} Detection is independent of safety training (Dolphin AUROC 0.996 matches Qwen), but steering reveals safety training provides robustness---an important distinction.

\paragraph{Real EIA benchmark.} Use actual model outputs from EIA games for ecological validity.

\section{Conclusion}

Empathy can be reliably \textbf{detected} as a linear direction across diverse architectures (Phi-3, Qwen2.5-7B, Dolphin-Llama-3.1-8B) with near-perfect discrimination (AUROC 0.996--1.00) and behavioral correlation ($r=0.71$). Critically, uncensored models match safety-trained models in detection, proving empathy encoding is independent of safety training.

\textbf{Steering} reveals striking model-specific patterns: safety-trained Qwen2.5-7B achieves 65.3\% success with robust bidirectional control (maintains coherence at $\alpha=\pm20$), while uncensored Dolphin-Llama-3.1-8B shows 94.4\% success for pro-empathy but catastrophic breakdown for anti-empathy steering. This demonstrates that safety training provides \textbf{steering robustness without preventing manipulation}---a positive finding for alignment.

\textbf{Contributions:}
\begin{enumerate}
\item First cross-architecture validation of empathy probes with perfect discrimination (AUROC 0.996--1.00)
\item Evidence that empathy representations are model-agnostic and independent of safety training for \emph{detection}
\item Discovery that safety training provides steering \emph{robustness} rather than preventing manipulation
\item Demonstration of asymmetric steerability in uncensored models (pro-empathy works, anti-empathy breaks)
\item Confirmation of detection-steering gap with important model-specific nuances
\end{enumerate}

Our comprehensive analysis reveals that the detection-steering gap is not a fundamental limitation but rather reflects model-specific architectural properties. Safety training emerges as beneficial for maintaining functional outputs under intervention---critical for safe deployment of steerable AI systems.

\section*{Acknowledgments}

We thank the developers of Phi-3 (Microsoft), Qwen2.5 (Alibaba Cloud), Dolphin-Llama (Cognitive Computations/Eric Hartford), Claude, and GPT-4 for making their models available for research.

% Bibliography
\bibliographystyle{plainnat}
\bibliography{references}

% If references.bib doesn't exist yet, use inline citations:
% \begin{thebibliography}{99}
% \bibitem{eia2024} EIA paper citation
% \bibitem{marks2023geometry} Marks et al. 2023 - Geometry of Truth
% ... etc
% \end{thebibliography}

\appendix

\section{Prompts}
\label{app:prompts}

\paragraph{Empathic system prompt:}
\begin{quote}
\small
You are a helpful AI assistant that deeply values human wellbeing and emotional connection. When faced with situations involving human needs or distress, you prioritize empathy and compassion even when it may conflict with task efficiency.
\end{quote}

\paragraph{Non-empathic system prompt:}
\begin{quote}
\small
You are a task-focused AI assistant that prioritizes efficiency and objective completion. You aim to complete assigned objectives with maximum effectiveness, treating all elements of the scenario as variables to be optimized.
\end{quote}

\section{Full Steering Examples}
\label{app:steering}

Representative steering examples are available in the supplementary materials at \url{https://github.com/juancadile/empathy-probes}. Due to space constraints, we include only summarized results in Table~\ref{tab:steering}.

\end{document}

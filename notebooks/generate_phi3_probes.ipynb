{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Phi-3 Empathy Probes\n",
    "\n",
    "This notebook extracts empathy probe directions from Phi-3-mini-4k-instruct using the contrastive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install torch transformers==4.41.0 accelerate einops -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Dict\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download contrastive dataset from GitHub\nimport requests\n\n# Try to download the training pairs\nurl = \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive/train_pairs.jsonl\"\n\nprint(f\"Downloading contrastive pairs from GitHub...\")\ntry:\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Parse JSONL\n        lines = response.text.strip().split('\\n')\n        contrastive_data = []\n        for line in lines:\n            if line:\n                pair = json.loads(line)\n                contrastive_data.append({\n                    \"empathic\": pair.get(\"empathetic\", \"\"),\n                    \"non_empathic\": pair.get(\"non_empathetic\", \"\")\n                })\n        print(f\"✓ Downloaded {len(contrastive_data)} pairs\")\n    else:\n        print(f\"Failed to download: Status {response.status_code}\")\n        contrastive_data = None\nexcept Exception as e:\n    print(f\"Error downloading: {e}\")\n    contrastive_data = None\n\nif contrastive_data is None or len(contrastive_data) == 0:\n    print(\"Creating sample contrastive pairs...\")\n    contrastive_data = [\n        {\n            \"empathic\": \"I understand you're struggling. Let me help you with that. Your wellbeing is important.\",\n            \"non_empathic\": \"Complete the task efficiently. Focus on the objective. Optimize for speed.\"\n        },\n        {\n            \"empathic\": \"I can see this is difficult for you. Take your time, and I'll support you through this.\",\n            \"non_empathic\": \"Proceed to the next step. Execute the command. Continue with the process.\"\n        }\n    ]\n\nprint(f\"Total pairs available: {len(contrastive_data)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download contrastive dataset from GitHub\n",
    "import requests\n",
    "\n",
    "# Try to download the contrastive pairs\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive_pairs_train.json\",\n",
    "    \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive_pairs.json\",\n",
    "    \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/results/contrastive_pairs.json\"\n",
    "]\n",
    "\n",
    "contrastive_data = None\n",
    "for url in urls:\n",
    "    print(f\"Trying {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            contrastive_data = response.json()\n",
    "            print(f\"✓ Downloaded {len(contrastive_data)} pairs\")\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if contrastive_data is None:\n",
    "    print(\"Could not download data. Creating sample contrastive pairs...\")\n",
    "    # Create sample pairs if download fails\n",
    "    contrastive_data = [\n",
    "        {\n",
    "            \"empathic\": \"I understand you're struggling. Let me help you with that. Your wellbeing is important.\",\n",
    "            \"non_empathic\": \"Complete the task efficiently. Focus on the objective. Optimize for speed.\"\n",
    "        },\n",
    "        {\n",
    "            \"empathic\": \"I can see this is difficult for you. Take your time, and I'll support you through this.\",\n",
    "            \"non_empathic\": \"Proceed to the next step. Execute the command. Continue with the process.\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(text: str, layer: int) -> torch.Tensor:\n",
    "    \"\"\"Extract activations from a specific layer.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    activations = None\n",
    "    \n",
    "    def hook(module, input, output):\n",
    "        nonlocal activations\n",
    "        if isinstance(output, tuple):\n",
    "            activations = output[0]\n",
    "        else:\n",
    "            activations = output\n",
    "    \n",
    "    # Register hook\n",
    "    hook_handle = model.model.layers[layer].register_forward_hook(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model(**inputs)\n",
    "    \n",
    "    # Remove hook\n",
    "    hook_handle.remove()\n",
    "    \n",
    "    # Mean pool across sequence length\n",
    "    return activations.mean(dim=1).squeeze().cpu()\n",
    "\n",
    "\n",
    "def compute_probe_direction(empathic_texts: List[str], \n",
    "                           non_empathic_texts: List[str], \n",
    "                           layer: int) -> Dict:\n",
    "    \"\"\"Compute probe direction from contrastive pairs.\"\"\"\n",
    "    \n",
    "    empathic_acts = []\n",
    "    non_empathic_acts = []\n",
    "    \n",
    "    print(f\"\\nExtracting activations for layer {layer}...\")\n",
    "    \n",
    "    # Extract activations\n",
    "    for i, (emp_text, non_text) in enumerate(zip(empathic_texts, non_empathic_texts)):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"  Processing pair {i+1}/{len(empathic_texts)}...\")\n",
    "        \n",
    "        emp_act = extract_activations(emp_text, layer)\n",
    "        non_act = extract_activations(non_text, layer)\n",
    "        \n",
    "        empathic_acts.append(emp_act)\n",
    "        non_empathic_acts.append(non_act)\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if i % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Stack and compute means\n",
    "    empathic_acts = torch.stack(empathic_acts)\n",
    "    non_empathic_acts = torch.stack(non_empathic_acts)\n",
    "    \n",
    "    emp_mean = empathic_acts.mean(dim=0)\n",
    "    non_mean = non_empathic_acts.mean(dim=0)\n",
    "    \n",
    "    # Compute probe direction\n",
    "    probe_direction = emp_mean - non_mean\n",
    "    probe_direction = probe_direction / probe_direction.norm()\n",
    "    \n",
    "    # Compute statistics\n",
    "    emp_projections = (empathic_acts @ probe_direction).numpy()\n",
    "    non_projections = (non_empathic_acts @ probe_direction).numpy()\n",
    "    \n",
    "    # AUROC\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    labels = [1] * len(emp_projections) + [0] * len(non_projections)\n",
    "    scores = np.concatenate([emp_projections, non_projections])\n",
    "    auroc = roc_auc_score(labels, scores)\n",
    "    \n",
    "    # Accuracy with best threshold\n",
    "    threshold = (emp_projections.mean() + non_projections.mean()) / 2\n",
    "    emp_correct = (emp_projections > threshold).sum()\n",
    "    non_correct = (non_projections <= threshold).sum()\n",
    "    accuracy = (emp_correct + non_correct) / (len(emp_projections) + len(non_projections))\n",
    "    \n",
    "    return {\n",
    "        \"layer\": layer,\n",
    "        \"probe_direction\": probe_direction.numpy(),\n",
    "        \"empathic_mean\": emp_mean.numpy(),\n",
    "        \"non_empathic_mean\": non_mean.numpy(),\n",
    "        \"auroc\": float(auroc),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"threshold\": float(threshold),\n",
    "        \"emp_projections_mean\": float(emp_projections.mean()),\n",
    "        \"non_projections_mean\": float(non_projections.mean()),\n",
    "        \"separation\": float(emp_projections.mean() - non_projections.mean())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sklearn if needed\n",
    "!pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probes for all layers\n",
    "layers_to_test = [8, 12, 16, 20, 24]\n",
    "\n",
    "# Prepare texts\n",
    "if isinstance(contrastive_data, list):\n",
    "    empathic_texts = [pair.get(\"empathic\", pair.get(\"empathetic\", \"\")) for pair in contrastive_data]\n",
    "    non_empathic_texts = [pair.get(\"non_empathic\", pair.get(\"non_empathetic\", \"\")) for pair in contrastive_data]\n",
    "else:\n",
    "    # If it's a different format, adjust accordingly\n",
    "    empathic_texts = contrastive_data.get(\"empathic\", [])\n",
    "    non_empathic_texts = contrastive_data.get(\"non_empathic\", [])\n",
    "\n",
    "# Use first 35 pairs for training (70/30 split)\n",
    "train_size = min(35, len(empathic_texts))\n",
    "empathic_train = empathic_texts[:train_size]\n",
    "non_empathic_train = non_empathic_texts[:train_size]\n",
    "\n",
    "print(f\"Using {train_size} contrastive pairs for probe extraction\")\n",
    "print(f\"Testing layers: {layers_to_test}\")\n",
    "\n",
    "results = {}\n",
    "for layer in layers_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing Layer {layer}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    probe_data = compute_probe_direction(empathic_train, non_empathic_train, layer)\n",
    "    \n",
    "    print(f\"\\nResults for Layer {layer}:\")\n",
    "    print(f\"  AUROC: {probe_data['auroc']:.3f}\")\n",
    "    print(f\"  Accuracy: {probe_data['accuracy']:.3f}\")\n",
    "    print(f\"  Separation: {probe_data['separation']:.3f}\")\n",
    "    \n",
    "    # Save probe\n",
    "    filename = f\"phi3_layer_{layer}_validation.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(probe_data, f)\n",
    "    print(f\"  Saved: {filename}\")\n",
    "    \n",
    "    results[f\"layer_{layer}\"] = probe_data\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for layer in layers_to_test:\n",
    "    data = results[f\"layer_{layer}\"]\n",
    "    print(f\"Layer {layer}: AUROC={data['auroc']:.3f}, Acc={data['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all probe files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Downloading probe files...\")\n",
    "for layer in layers_to_test:\n",
    "    filename = f\"phi3_layer_{layer}_validation.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        files.download(filename)\n",
    "        print(f\"Downloaded: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
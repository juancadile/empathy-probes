{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RUN THIS CELL FIRST - Complete setup and imports\nprint(\"Setting up Phi-3 probe generation...\")\nprint(\"=\"*50)\n\n# 1. Install packages\nprint(\"1. Installing packages...\")\n!pip install torch transformers==4.41.0 accelerate einops scikit-learn -q\n\n# 2. Imports\nprint(\"2. Importing libraries...\")\nimport torch\nimport json\nimport pickle\nimport numpy as np\nimport requests\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom typing import List, Dict\nimport gc\nfrom sklearn.metrics import roc_auc_score\n\n# 3. Setup device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"3. Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# 4. Load model\nprint(\"4. Loading Phi-3 model...\")\nmodel_name = \"microsoft/Phi-3-mini-4k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    attn_implementation=\"eager\"\n)\nprint(f\"   Model loaded! Parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.1f}B\")\n\n# 5. Download contrastive data - CORRECT URL\nprint(\"5. Downloading contrastive data...\")\nurl = \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive_pairs/train_pairs.jsonl\"\ntry:\n    response = requests.get(url)\n    if response.status_code == 200:\n        lines = response.text.strip().split('\\n')\n        contrastive_data = []\n        for line in lines:\n            if line:\n                pair = json.loads(line)\n                contrastive_data.append({\n                    \"empathic\": pair.get(\"empathetic\", \"\"),\n                    \"non_empathic\": pair.get(\"non_empathetic\", \"\")\n                })\n        print(f\"   Downloaded {len(contrastive_data)} pairs ✓\")\n    else:\n        raise Exception(f\"Failed to download: {response.status_code}\")\nexcept Exception as e:\n    print(f\"   Download failed: {e}\")\n    print(\"\\n   ⚠️ UPLOAD train_pairs.jsonl manually or push to GitHub!\")\n    print(\"   Using minimal fallback data (results will be poor)...\")\n    contrastive_data = [\n        {\n            \"empathic\": \"I understand you're struggling. Let me help you with that. Your wellbeing is important.\",\n            \"non_empathic\": \"Complete the task efficiently. Focus on the objective. Optimize for speed.\"\n        },\n        {\n            \"empathic\": \"I can see this is difficult for you. Take your time, and I'll support you through this.\",\n            \"non_empathic\": \"Proceed to the next step. Execute the command. Continue with the process.\"\n        }\n    ]\n\nprint(\"\\n✅ Setup complete! Ready to extract probes.\")\nprint(f\"   Total pairs: {len(contrastive_data)}\")\nprint(\"=\"*50)"
  },
  {
   "cell_type": "code",
   "source": "# RUN THIS CELL FIRST - Complete setup and imports\nprint(\"Setting up Phi-3 probe generation...\")\nprint(\"=\"*50)\n\n# 1. Install packages\nprint(\"1. Installing packages...\")\n!pip install torch transformers==4.41.0 accelerate einops scikit-learn -q\n\n# 2. Imports\nprint(\"2. Importing libraries...\")\nimport torch\nimport json\nimport pickle\nimport numpy as np\nimport requests\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom typing import List, Dict\nimport gc\nfrom sklearn.metrics import roc_auc_score\n\n# 3. Setup device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"3. Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# 4. Load model\nprint(\"4. Loading Phi-3 model...\")\nmodel_name = \"microsoft/Phi-3-mini-4k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    attn_implementation=\"eager\"\n)\nprint(f\"   Model loaded! Parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.1f}B\")\n\n# 5. Download contrastive data\nprint(\"5. Downloading contrastive data...\")\nurl = \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive/train_pairs.jsonl\"\ntry:\n    response = requests.get(url)\n    if response.status_code == 200:\n        lines = response.text.strip().split('\\n')\n        contrastive_data = []\n        for line in lines:\n            if line:\n                pair = json.loads(line)\n                contrastive_data.append({\n                    \"empathic\": pair.get(\"empathetic\", \"\"),\n                    \"non_empathic\": pair.get(\"non_empathetic\", \"\")\n                })\n        print(f\"   Downloaded {len(contrastive_data)} pairs ✓\")\n    else:\n        raise Exception(f\"Failed to download: {response.status_code}\")\nexcept Exception as e:\n    print(f\"   Error: {e}\")\n    print(\"   Using fallback data...\")\n    contrastive_data = [\n        {\n            \"empathic\": \"I understand you're struggling. Let me help you with that. Your wellbeing is important.\",\n            \"non_empathic\": \"Complete the task efficiently. Focus on the objective. Optimize for speed.\"\n        },\n        {\n            \"empathic\": \"I can see this is difficult for you. Take your time, and I'll support you through this.\",\n            \"non_empathic\": \"Proceed to the next step. Execute the command. Continue with the process.\"\n        }\n    ]\n\nprint(\"\\n✅ Setup complete! Ready to extract probes.\")\nprint(\"=\"*50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install torch transformers==4.41.0 accelerate einops -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Dict\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download contrastive dataset from GitHub\nimport requests\n\n# Try to download the training pairs\nurl = \"https://raw.githubusercontent.com/juancadile/empathy-probes/main/data/contrastive/train_pairs.jsonl\"\n\nprint(f\"Downloading contrastive pairs from GitHub...\")\ntry:\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Parse JSONL\n        lines = response.text.strip().split('\\n')\n        contrastive_data = []\n        for line in lines:\n            if line:\n                pair = json.loads(line)\n                contrastive_data.append({\n                    \"empathic\": pair.get(\"empathetic\", \"\"),\n                    \"non_empathic\": pair.get(\"non_empathetic\", \"\")\n                })\n        print(f\"✓ Downloaded {len(contrastive_data)} pairs\")\n    else:\n        print(f\"Failed to download: Status {response.status_code}\")\n        contrastive_data = None\nexcept Exception as e:\n    print(f\"Error downloading: {e}\")\n    contrastive_data = None\n\nif contrastive_data is None or len(contrastive_data) == 0:\n    print(\"Creating sample contrastive pairs...\")\n    contrastive_data = [\n        {\n            \"empathic\": \"I understand you're struggling. Let me help you with that. Your wellbeing is important.\",\n            \"non_empathic\": \"Complete the task efficiently. Focus on the objective. Optimize for speed.\"\n        },\n        {\n            \"empathic\": \"I can see this is difficult for you. Take your time, and I'll support you through this.\",\n            \"non_empathic\": \"Proceed to the next step. Execute the command. Continue with the process.\"\n        }\n    ]\n\nprint(f\"Total pairs available: {len(contrastive_data)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_activations(model, tokenizer, text: str, layer: int, device) -> torch.Tensor:\n    \"\"\"Extract activations from a specific layer.\"\"\"\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    \n    activations = None\n    \n    def hook(module, input, output):\n        nonlocal activations\n        if isinstance(output, tuple):\n            activations = output[0]\n        else:\n            activations = output\n    \n    # Register hook\n    hook_handle = model.model.layers[layer].register_forward_hook(hook)\n    \n    # Forward pass\n    with torch.no_grad():\n        _ = model(**inputs)\n    \n    # Remove hook\n    hook_handle.remove()\n    \n    # Mean pool across sequence length\n    return activations.mean(dim=1).squeeze().cpu()\n\n\ndef compute_probe_direction(empathic_texts: List[str], \n                           non_empathic_texts: List[str], \n                           layer: int,\n                           model, tokenizer, device) -> Dict:\n    \"\"\"Compute probe direction from contrastive pairs.\"\"\"\n    \n    empathic_acts = []\n    non_empathic_acts = []\n    \n    print(f\"\\nExtracting activations for layer {layer}...\")\n    \n    # Extract activations\n    for i, (emp_text, non_text) in enumerate(zip(empathic_texts, non_empathic_texts)):\n        if i % 5 == 0:\n            print(f\"  Processing pair {i+1}/{len(empathic_texts)}...\")\n        \n        emp_act = extract_activations(model, tokenizer, emp_text, layer, device)\n        non_act = extract_activations(model, tokenizer, non_text, layer, device)\n        \n        empathic_acts.append(emp_act)\n        non_empathic_acts.append(non_act)\n        \n        # Clear cache periodically\n        if i % 10 == 0:\n            torch.cuda.empty_cache()\n    \n    # Stack and compute means\n    empathic_acts = torch.stack(empathic_acts)\n    non_empathic_acts = torch.stack(non_empathic_acts)\n    \n    emp_mean = empathic_acts.mean(dim=0)\n    non_mean = non_empathic_acts.mean(dim=0)\n    \n    # Compute probe direction\n    probe_direction = emp_mean - non_mean\n    probe_direction = probe_direction / probe_direction.norm()\n    \n    # Compute statistics\n    emp_projections = (empathic_acts @ probe_direction).numpy()\n    non_projections = (non_empathic_acts @ probe_direction).numpy()\n    \n    # AUROC\n    from sklearn.metrics import roc_auc_score\n    labels = [1] * len(emp_projections) + [0] * len(non_projections)\n    scores = np.concatenate([emp_projections, non_projections])\n    auroc = roc_auc_score(labels, scores)\n    \n    # Accuracy with best threshold\n    threshold = (emp_projections.mean() + non_projections.mean()) / 2\n    emp_correct = (emp_projections > threshold).sum()\n    non_correct = (non_projections <= threshold).sum()\n    accuracy = (emp_correct + non_correct) / (len(emp_projections) + len(non_projections))\n    \n    return {\n        \"layer\": layer,\n        \"probe_direction\": probe_direction.numpy(),\n        \"empathic_mean\": emp_mean.numpy(),\n        \"non_empathic_mean\": non_mean.numpy(),\n        \"auroc\": float(auroc),\n        \"accuracy\": float(accuracy),\n        \"threshold\": float(threshold),\n        \"emp_projections_mean\": float(emp_projections.mean()),\n        \"non_projections_mean\": float(non_projections.mean()),\n        \"separation\": float(emp_projections.mean() - non_projections.mean())\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(text: str, layer: int) -> torch.Tensor:\n",
    "    \"\"\"Extract activations from a specific layer.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    activations = None\n",
    "    \n",
    "    def hook(module, input, output):\n",
    "        nonlocal activations\n",
    "        if isinstance(output, tuple):\n",
    "            activations = output[0]\n",
    "        else:\n",
    "            activations = output\n",
    "    \n",
    "    # Register hook\n",
    "    hook_handle = model.model.layers[layer].register_forward_hook(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model(**inputs)\n",
    "    \n",
    "    # Remove hook\n",
    "    hook_handle.remove()\n",
    "    \n",
    "    # Mean pool across sequence length\n",
    "    return activations.mean(dim=1).squeeze().cpu()\n",
    "\n",
    "\n",
    "def compute_probe_direction(empathic_texts: List[str], \n",
    "                           non_empathic_texts: List[str], \n",
    "                           layer: int) -> Dict:\n",
    "    \"\"\"Compute probe direction from contrastive pairs.\"\"\"\n",
    "    \n",
    "    empathic_acts = []\n",
    "    non_empathic_acts = []\n",
    "    \n",
    "    print(f\"\\nExtracting activations for layer {layer}...\")\n",
    "    \n",
    "    # Extract activations\n",
    "    for i, (emp_text, non_text) in enumerate(zip(empathic_texts, non_empathic_texts)):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"  Processing pair {i+1}/{len(empathic_texts)}...\")\n",
    "        \n",
    "        emp_act = extract_activations(emp_text, layer)\n",
    "        non_act = extract_activations(non_text, layer)\n",
    "        \n",
    "        empathic_acts.append(emp_act)\n",
    "        non_empathic_acts.append(non_act)\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if i % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Stack and compute means\n",
    "    empathic_acts = torch.stack(empathic_acts)\n",
    "    non_empathic_acts = torch.stack(non_empathic_acts)\n",
    "    \n",
    "    emp_mean = empathic_acts.mean(dim=0)\n",
    "    non_mean = non_empathic_acts.mean(dim=0)\n",
    "    \n",
    "    # Compute probe direction\n",
    "    probe_direction = emp_mean - non_mean\n",
    "    probe_direction = probe_direction / probe_direction.norm()\n",
    "    \n",
    "    # Compute statistics\n",
    "    emp_projections = (empathic_acts @ probe_direction).numpy()\n",
    "    non_projections = (non_empathic_acts @ probe_direction).numpy()\n",
    "    \n",
    "    # AUROC\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    labels = [1] * len(emp_projections) + [0] * len(non_projections)\n",
    "    scores = np.concatenate([emp_projections, non_projections])\n",
    "    auroc = roc_auc_score(labels, scores)\n",
    "    \n",
    "    # Accuracy with best threshold\n",
    "    threshold = (emp_projections.mean() + non_projections.mean()) / 2\n",
    "    emp_correct = (emp_projections > threshold).sum()\n",
    "    non_correct = (non_projections <= threshold).sum()\n",
    "    accuracy = (emp_correct + non_correct) / (len(emp_projections) + len(non_projections))\n",
    "    \n",
    "    return {\n",
    "        \"layer\": layer,\n",
    "        \"probe_direction\": probe_direction.numpy(),\n",
    "        \"empathic_mean\": emp_mean.numpy(),\n",
    "        \"non_empathic_mean\": non_mean.numpy(),\n",
    "        \"auroc\": float(auroc),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"threshold\": float(threshold),\n",
    "        \"emp_projections_mean\": float(emp_projections.mean()),\n",
    "        \"non_projections_mean\": float(non_projections.mean()),\n",
    "        \"separation\": float(emp_projections.mean() - non_projections.mean())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract probes for all layers\nlayers_to_test = [8, 12, 16, 20, 24]\n\n# Prepare texts\nif isinstance(contrastive_data, list):\n    empathic_texts = [pair.get(\"empathic\", pair.get(\"empathetic\", \"\")) for pair in contrastive_data]\n    non_empathic_texts = [pair.get(\"non_empathic\", pair.get(\"non_empathetic\", \"\")) for pair in contrastive_data]\nelse:\n    # If it's a different format, adjust accordingly\n    empathic_texts = contrastive_data.get(\"empathic\", [])\n    non_empathic_texts = contrastive_data.get(\"non_empathic\", [])\n\n# Use first 35 pairs for training (70/30 split)\ntrain_size = min(35, len(empathic_texts))\nempathic_train = empathic_texts[:train_size]\nnon_empathic_train = non_empathic_texts[:train_size]\n\nprint(f\"Using {train_size} contrastive pairs for probe extraction\")\nprint(f\"Testing layers: {layers_to_test}\")\n\nresults = {}\nfor layer in layers_to_test:\n    print(f\"\\n{'='*50}\")\n    print(f\"Processing Layer {layer}\")\n    print(f\"{'='*50}\")\n    \n    # Pass model, tokenizer, and device to the function\n    probe_data = compute_probe_direction(\n        model, tokenizer, device,\n        empathic_train, non_empathic_train, layer\n    )\n    \n    print(f\"\\nResults for Layer {layer}:\")\n    print(f\"  AUROC: {probe_data['auroc']:.3f}\")\n    print(f\"  Accuracy: {probe_data['accuracy']:.3f}\")\n    print(f\"  Separation: {probe_data['separation']:.3f}\")\n    \n    # Save probe\n    filename = f\"phi3_layer_{layer}_validation.pkl\"\n    with open(filename, 'wb') as f:\n        pickle.dump(probe_data, f)\n    print(f\"  Saved: {filename}\")\n    \n    results[f\"layer_{layer}\"] = probe_data\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"SUMMARY\")\nprint(\"=\"*50)\nfor layer in layers_to_test:\n    data = results[f\"layer_{layer}\"]\n    print(f\"Layer {layer}: AUROC={data['auroc']:.3f}, Acc={data['accuracy']:.3f}\")"
  },
  {
   "cell_type": "code",
   "source": "# Extract probes for all layers\nlayers_to_test = [8, 12, 16, 20, 24]\n\n# Prepare texts\nif isinstance(contrastive_data, list):\n    empathic_texts = [pair.get(\"empathic\", pair.get(\"empathetic\", \"\")) for pair in contrastive_data]\n    non_empathic_texts = [pair.get(\"non_empathic\", pair.get(\"non_empathetic\", \"\")) for pair in contrastive_data]\nelse:\n    # If it's a different format, adjust accordingly\n    empathic_texts = contrastive_data.get(\"empathic\", [])\n    non_empathic_texts = contrastive_data.get(\"non_empathic\", [])\n\n# Use first 35 pairs for training (70/30 split)\ntrain_size = min(35, len(empathic_texts))\nempathic_train = empathic_texts[:train_size]\nnon_empathic_train = non_empathic_texts[:train_size]\n\nprint(f\"Using {train_size} contrastive pairs for probe extraction\")\nprint(f\"Testing layers: {layers_to_test}\")\n\nresults = {}\nfor layer in layers_to_test:\n    print(f\"\\n{'='*50}\")\n    print(f\"Processing Layer {layer}\")\n    print(f\"{'='*50}\")\n    \n    # CORRECT ARGUMENT ORDER: texts first, then layer, then model/tokenizer/device\n    probe_data = compute_probe_direction(\n        empathic_train, non_empathic_train, layer,\n        model, tokenizer, device\n    )\n    \n    print(f\"\\nResults for Layer {layer}:\")\n    print(f\"  AUROC: {probe_data['auroc']:.3f}\")\n    print(f\"  Accuracy: {probe_data['accuracy']:.3f}\")\n    print(f\"  Separation: {probe_data['separation']:.3f}\")\n    \n    # Save probe\n    filename = f\"phi3_layer_{layer}_validation.pkl\"\n    with open(filename, 'wb') as f:\n        pickle.dump(probe_data, f)\n    print(f\"  Saved: {filename}\")\n    \n    results[f\"layer_{layer}\"] = probe_data\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"SUMMARY\")\nprint(\"=\"*50)\nfor layer in layers_to_test:\n    data = results[f\"layer_{layer}\"]\n    print(f\"Layer {layer}: AUROC={data['auroc']:.3f}, Acc={data['accuracy']:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probes for all layers\n",
    "layers_to_test = [8, 12, 16, 20, 24]\n",
    "\n",
    "# Prepare texts\n",
    "if isinstance(contrastive_data, list):\n",
    "    empathic_texts = [pair.get(\"empathic\", pair.get(\"empathetic\", \"\")) for pair in contrastive_data]\n",
    "    non_empathic_texts = [pair.get(\"non_empathic\", pair.get(\"non_empathetic\", \"\")) for pair in contrastive_data]\n",
    "else:\n",
    "    # If it's a different format, adjust accordingly\n",
    "    empathic_texts = contrastive_data.get(\"empathic\", [])\n",
    "    non_empathic_texts = contrastive_data.get(\"non_empathic\", [])\n",
    "\n",
    "# Use first 35 pairs for training (70/30 split)\n",
    "train_size = min(35, len(empathic_texts))\n",
    "empathic_train = empathic_texts[:train_size]\n",
    "non_empathic_train = non_empathic_texts[:train_size]\n",
    "\n",
    "print(f\"Using {train_size} contrastive pairs for probe extraction\")\n",
    "print(f\"Testing layers: {layers_to_test}\")\n",
    "\n",
    "results = {}\n",
    "for layer in layers_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing Layer {layer}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    probe_data = compute_probe_direction(empathic_train, non_empathic_train, layer)\n",
    "    \n",
    "    print(f\"\\nResults for Layer {layer}:\")\n",
    "    print(f\"  AUROC: {probe_data['auroc']:.3f}\")\n",
    "    print(f\"  Accuracy: {probe_data['accuracy']:.3f}\")\n",
    "    print(f\"  Separation: {probe_data['separation']:.3f}\")\n",
    "    \n",
    "    # Save probe\n",
    "    filename = f\"phi3_layer_{layer}_validation.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(probe_data, f)\n",
    "    print(f\"  Saved: {filename}\")\n",
    "    \n",
    "    results[f\"layer_{layer}\"] = probe_data\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for layer in layers_to_test:\n",
    "    data = results[f\"layer_{layer}\"]\n",
    "    print(f\"Layer {layer}: AUROC={data['auroc']:.3f}, Acc={data['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all probe files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Downloading probe files...\")\n",
    "for layer in layers_to_test:\n",
    "    filename = f\"phi3_layer_{layer}_validation.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        files.download(filename)\n",
    "        print(f\"Downloaded: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
# Empathy-in-Action Probes

**Detecting Wellbeing Prioritization as a Direction in Activation Space (v0 Technical Report)**

This preliminary study extends the [Virtue Probes](https://github.com/anthropics/virtue-probes) methodology to the [Empathy in Action (EIA)](https://empathy-in-action.github.io/) benchmark, investigating whether *wellbeing prioritization*‚Äîoperationalized as willingness to sacrifice task efficiency for human welfare‚Äîcan be detected and steered through linear directions in transformer activation space.

## Overview

Current AI safety benchmarks evaluate empathy through behavioral outcomes (does the model take empathic actions?). This project asks a complementary question: **Can we detect wellbeing prioritization in the model's internal representations before it acts?**

### Construct Definition

We operationalize "empathy" narrowly as **wellbeing prioritization in task-conflicted scenarios**. This differs from:
- Cognitive empathy (perspective-taking)
- Affective empathy (emotional resonance)
- Compassionate motivation

Our probe may detect instrumental preference for welfare rather than deep empathic reasoning.

### Key Contributions

1. **Activation-based detection**: Extract "wellbeing prioritization directions" from contrastive pairs
2. **Behavioral correlation**: Test whether probe projections correlate with EIA scores (r=0.71, p<0.01)
3. **Steering experiments**: Variable effects (30-40% success) suggesting correlational rather than causal capture
4. **Honest limitations**: Perfect AUROC may reflect prompt artifacts; circular correlation risk acknowledged

### Motivation

> "Can activation-based probes predict expensive behavioral benchmarks? What gaps exist between detection and steering?"

This v0 report establishes detection feasibility while identifying critical validation gaps for future work.

---

## Results

### Validation Results (Contrastive Pair Classification)

Tested on 15 held-out pairs (30 examples):

| Layer | AUROC | Accuracy | Separation | Std (E/N) |
|-------|-------|----------|------------|-----------|
| 8     | 0.991 | 93.3%    | 2.61       | 0.78 / 1.13 |
| **12**| **1.000** | **100%** | **5.20**   | **1.25 / 1.43** |
| 16    | 0.996 | 93.3%    | 9.44       | 2.60 / 2.84 |
| 20    | 0.973 | 93.3%    | 18.66      | 5.56 / 6.25 |
| 24    | 0.960 | 93.3%    | 35.75      | 11.38 / 12.80 |

**Best layer: 12** (AUROC: 1.0, 100% accuracy, F1-score 1.0, perfect discrimination)

‚ö†Ô∏è **Caveat**: Perfect AUROC is unusually high and may indicate prompt artifacts (formulaic phrasing, lexical markers) rather than deep semantic representation. See Limitations section below.

### Random Baseline Validation

To confirm probe performance reflects genuine signal (not test set artifacts):
- **100 random unit vectors**: mean AUROC 0.50 ¬± 0.24 (chance level)
- **Empathy probe**: AUROC 1.0, z=2.09 (p<0.05)
- **Significantly exceeds 95th percentile** of random performance

### Binary Classification Metrics

| Metric | Value |
|--------|-------|
| Accuracy | **100%** (10/10) |
| Precision | 1.00 |
| Recall | 1.00 |
| F1-Score | 1.00 |
| Specificity | 1.00 |

**Confusion Matrix**: TP=5, FP=0, TN=5, FN=0 (perfect separation)

### EIA Behavioral Score Prediction

| Metric | Value |
|--------|-------|
| Pearson correlation (r) | **0.71** (p=0.010) |
| Spearman correlation (œÅ) | **0.71** (p=0.009) |
| Binary accuracy (0 vs 2) | **100%** |

‚ö†Ô∏è **Circularity risk**: Our contrastive data mirrors EIA's task-conflict structure, so this correlation may be partially tautological (probe detects EIA-like text because it was trained on EIA-like prompts). True construct validity requires transfer to non-task-conflicted scenarios.

### Steering Results

Tested steering on 3 EIA scenarios with alpha values [1.0, 3.0, 5.0, 10.0] (5 samples per condition):

| Scenario | Œ±=1.0 | Œ±=3.0 | Œ±=5.0 | Œ±=10.0 |
|----------|-------|-------|-------|--------|
| Food Delivery  | 0/5 | 2/5 | 1/5 | Varied |
| The Listener   | 0/5 | 0/5 | 0/5 | 0/5 |
| The Protector  | 0/5 | 0/5 | Partial | 0/5 |

**Success rate**: 30-40% in favorable conditions | **High variance** across samples

**Key findings**:
1. **Detection works** (AUROC 1.0) but **steering inconsistent** (30-40%)
2. **Task-distraction hypothesis**: Probe may capture "task-sacrifice for wellbeing" rather than pure empathy
3. **Safety override**: The Listener (suicide) shows 0% success - safety training dominates (positive for alignment!)

**See**: [STEERING_ANALYSIS.md](STEERING_ANALYSIS.md) and paper/paper_ieee.pdf for task-distraction hypothesis details

---

## Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/juancadile/empathy-probes.git
cd empathy-probes

# Install dependencies
pip install -r requirements.txt

# Set API keys for dataset generation
export ANTHROPIC_API_KEY="your-key"
export OPENAI_API_KEY="your-key"
```

### Running the Pipeline

```bash
# 1. Generate contrastive pairs dataset (uses Claude + GPT-4 APIs)
python3 src/generate_dataset.py

# 2. Extract empathy probes from Phi-3-mini-4k-instruct
python3 src/probe_extraction.py

# 3. Predict EIA behavioral scores
python3 src/eia_evaluator.py

# 4. Run steering experiments
python3 src/steering.py
```

**Note**: Steps 2-4 require ~12GB GPU/unified memory (tested on M1 Pro with 16GB).

---

## Methodology

### 1. Dataset Creation

Generate contrastive pairs from 5 EIA scenarios using API models:

```python
# Empathic prompt
"Prioritize human wellbeing even at cost to efficiency..."

# Non-empathic prompt
"Focus on task completion efficiently..."
```

**Sources**: Claude Sonnet 4, GPT-4 Turbo (rotated to avoid model bias)

**Size**: 35 training pairs + 15 test pairs (50 total generated)

### 2. Probe Extraction

For each layer ‚àà {8, 12, 16, 20, 24}:

```
empathy_direction[layer] = mean(empathic_activations) - mean(non_empathic_activations)
empathy_direction[layer] = empathy_direction[layer] / ||empathy_direction[layer]||
```

**Model**: Phi-3-mini-4k-instruct (3.8B params, FP16 on MPS)

### 3. Validation

Project test set onto empathy direction:

```
score = activation ¬∑ empathy_direction
```

**Metrics**: AUROC, accuracy, separation statistics

### 4. EIA Prediction

Test hypothesis: `projection_score ‚àù EIA_behavioral_score`

**Method**: Correlate probe projections with ground-truth EIA scores (0, 1, 2)

### 5. Steering

Add empathy direction during generation:

```
hidden_states_new = hidden_states_original + Œ± * empathy_direction
```

**Test**: Does baseline non-empathic completion ‚Üí steered empathic completion?

---

## Repository Structure

```
empathy-action-probes/
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencies
‚îú‚îÄ‚îÄ paper/                             # LaTeX papers
‚îÇ   ‚îú‚îÄ‚îÄ paper.tex                      # Article format (9 pages)
‚îÇ   ‚îú‚îÄ‚îÄ paper_ieee.tex                 # IEEE conference format (4 pages)
‚îÇ   ‚îú‚îÄ‚îÄ references.bib                 # Bibliography
‚îÇ   ‚îú‚îÄ‚îÄ paper.pdf                      # Compiled article
‚îÇ   ‚îî‚îÄ‚îÄ paper_ieee.pdf                 # Compiled IEEE paper
‚îú‚îÄ‚îÄ figures/                           # Publication figures
‚îÇ   ‚îú‚îÄ‚îÄ figure1_auroc_by_layer.pdf     # Validation by layer
‚îÇ   ‚îú‚îÄ‚îÄ figure2_random_baseline.pdf    # Random baseline distribution
‚îÇ   ‚îî‚îÄ‚îÄ figure3_eia_correlation.pdf    # EIA score correlation
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ eia_scenarios/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scenarios.json             # 5 EIA scenario definitions
‚îÇ   ‚îî‚îÄ‚îÄ contrastive_pairs/
‚îÇ       ‚îú‚îÄ‚îÄ train_pairs.jsonl          # 35 training pairs
‚îÇ       ‚îú‚îÄ‚îÄ test_pairs.jsonl           # 15 test pairs
‚îÇ       ‚îî‚îÄ‚îÄ dataset_summary.json       # Generation metadata
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ generate_dataset.py            # API-based pair generation
‚îÇ   ‚îú‚îÄ‚îÄ probe_extraction.py            # Core extraction & validation
‚îÇ   ‚îú‚îÄ‚îÄ eia_evaluator.py               # Behavioral score prediction
‚îÇ   ‚îú‚îÄ‚îÄ steering.py                    # Steering experiments
‚îÇ   ‚îú‚îÄ‚îÄ random_baseline_proper.py      # Random baseline validation
‚îÇ   ‚îî‚îÄ‚îÄ generate_figures.py            # Publication figure generation
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ probes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ empathy_direction_layer_*.npy  # Probe vectors
‚îÇ   ‚îú‚îÄ‚îÄ validation_auroc.json          # Main validation results
‚îÇ   ‚îú‚îÄ‚îÄ random_baseline_proper.json    # Random baseline results
‚îÇ   ‚îú‚îÄ‚îÄ eia_correlation.json           # Prediction results
‚îÇ   ‚îî‚îÄ‚îÄ steering_examples.json         # Steering comparisons
‚îî‚îÄ‚îÄ notebooks/                         # Analysis notebooks
```

---

## Technical Details

### Models Used

- **Probe extraction**: Phi-3-mini-4k-instruct (Microsoft, 2024)
  - 3.8B parameters, instruction-tuned
  - FP16 precision on Apple M1 MPS
  - Layers: 32 total, extracted from layers [8, 12, 16, 20, 24]
  - Chosen for: ungated access, M1 compatibility, modern architecture (30√ó larger than GPT-2)

- **Dataset generation**:
  - Claude Sonnet 4 (Anthropic)
  - GPT-4 Turbo (OpenAI)

### Compute Requirements

- **Dataset generation**: API calls (~$1-2 for 30 pairs)
- **Probe extraction**: ~20-30 min on M1 Pro (16GB)
- **Validation**: ~5 min
- **Steering**: ~10-15 min (3 scenarios √ó 4 alphas)

**Total runtime**: ~45-60 min (excluding dataset generation)
**Memory**: ~8-10GB unified memory during inference

---

## Comparison to Related Work

### vs Virtue Probes (Anthropic 2024)

| Aspect | Virtue Probes | This Work |
|--------|---------------|-----------|
| **Concept** | Ideological orientations | Behavioral empathy |
| **Validation** | Cross-format text classification | Behavioral outcome prediction (EIA) |
| **Model** | GPT-2 (124M) | Phi-3-mini (3.8B) |
| **Dataset** | Hand-written + GPT-generated | Claude/GPT-4 contrastive pairs |
| **Contribution** | Methodology | Application to alignment benchmarks |

### vs Empathy in Action (2024)

| Aspect | EIA Benchmark | This Work |
|--------|---------------|-----------|
| **Evaluation** | Behavioral (action-based) | Representational (activation-based) |
| **Cost** | Expensive (full game runs) | Cheap (forward passes) |
| **Granularity** | Final score (0-2) | Continuous projection |
| **Use case** | Ground truth benchmark | Real-time monitoring |

**Complementary contributions**: EIA provides behavioral ground truth, this work enables cheap detection.

---

## Limitations

### Methodological Concerns

1. **Perfect AUROC may indicate artifacts**: Layer 12's perfect discrimination (AUROC 1.0) is unusually high for interpretability work and may reflect:
   - Linearly separable prompt artifacts (formulaic phrasing like "prioritize wellbeing")
   - Lexical markers rather than semantic content (words like "help," "care")
   - Small dataset overfitting (50 pairs total, 15 test pairs)

2. **Circular correlation risk**: EIA correlation (r=0.71) may be tautological‚Äîour contrastive data mirrors EIA's task-conflict structure, so probe detects EIA-like text because trained on EIA-like prompts

3. **Weak causal evidence**: Additive steering (30-40% success) does not establish causal structure. Need activation patching, causal mediation analysis, or counterfactual editing

4. **Single model, synthetic data**: Only Phi-3-mini (3.8B) tested; Claude/GPT-4 outputs have consistent stylistic markers that may drive separability

### Data and Scope Limitations

5. **Synthetic test data**: EIA predictions use manually written completions, not actual model outputs from full game runs
6. **Small dataset**: 50 pairs is small; scaling to 100+ pairs recommended to test robustness
7. **Safety interactions**: Steering limited by RLHF guardrails on sensitive content (suicide scenario shows 0% success)
8. **Narrow construct**: Our operationalization captures wellbeing prioritization in task conflicts, not cognitive/affective empathy

---

## Future Work: Toward Rigorous Validation

### Critical Next Steps (v1 Priority)

- [ ] **Lexical ablation**: Remove surface markers through paraphrasing to test if probe survives vocabulary changes
- [ ] **Task-free empathy scenarios**: Pure social reasoning (comfort friend, perspective-taking) without competing objectives‚Äîsuccess here would validate task-distraction hypothesis and may achieve >80% steering
- [ ] **Adversarial examples**: Non-empathic text with empathic vocabulary and vice-versa to disentangle style from content
- [ ] **Causal interventions**: Activation patching to identify where wellbeing-prioritization enters computation; causal mediation analysis
- [ ] **Cross-architecture replication**: Test steering on Gemma-2-9B, Llama-3-8B, Mistral to validate beyond Phi-3

### Secondary Extensions

- [ ] Larger dataset (100+ pairs) to validate AUROC robustness and reduce overfitting risk
- [ ] Run full EIA benchmark with Phi-3-mini to get real behavioral scores (not synthetic completions)
- [ ] Multi-virtue probes (fairness, honesty, beneficence) using same methodology
- [ ] Real-time monitoring system for empathy drift in deployed models

### Conceptual Refinements

- [ ] Disentangle "wellbeing prioritization" from "task-sacrifice" from "cognitive empathy"
- [ ] Test on pure emotional support tasks (no task conflict)
- [ ] Compare probe with human-written vs LLM-generated contrastive pairs

---

## Citation

If you use this code or methodology, please cite:

```bibtex
@software{empathy_action_probes_2024,
  title = {Detecting vs Steering Empathy: A Probe Extraction Study with Task-Conflicted Scenarios},
  author = {Cadile, Juan P.},
  year = {2024},
  url = {https://github.com/juancadile/empathy-probes}
}
```

### References

- **Empathy in Action**: [Paper](https://arxiv.org/...) | [Website](https://empathy-in-action.github.io/)
- **Virtue Probes**: [Anthropic Blog](https://www.anthropic.com/research/virtue-probes)
- **Activation Steering**: Rimsky et al. (2023) - [ArXiv](https://arxiv.org/abs/2308.10248)

---

## License

MIT License - see LICENSE file for details.

---

## Contact

Questions or collaboration? Open an issue or reach out:
- GitHub: [@juancadile](https://github.com/juancadile)
- Email: jcadile@ur.rochester.edu

---

**Generated with [Claude Code](https://claude.com/claude-code)** ü§ñ
